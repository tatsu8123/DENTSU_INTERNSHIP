# 課題１ 手書き数字（MNIST）分類問題
はじめに
----
ローカル環境の都合上、google colabでの実験しか行っていません。
そのため、実験結果を見る際は'DENTSU_kadai1_colab.ipynb'をご覧ください。
お手元の環境で実行される際は'DENTSU_kadai1.ipynb'の最初のセルにあるdata_pathを変更するようお願いします。。


データセット作成
----
### データの前処理、データセットの作成方法について
まず前提として、sklearnからダウンロードした画像データを変数X、ラベルデータを変数yに格納しています。

データの前処理としては、まず収束速度を早めるために画像データXの正規化を行います。 
次に、後述するpytorchで取り扱い可能な形にするために、ラベルデータyを数値にし、Xのshapeを変えます。

データセットの作成方法としては、sklearnのtrain_test_splitを用いて画像データXとラベルデータyを分割しました。


### 学習データ、バリデーションデータ、テストデータの分け方や説明変数の作成方法等について
データセットについては、手書き文字の画像データ(MNIST)の画像データ70000枚は学習データ60000枚、テストデータ10000枚に分割しました。この際、学習データにおいてはランダムな順番で入力されるようにしています。 
一クラスあたり6000枚の学習データが用意されることになり、学習データ数が画像データの入力次元784次元を大幅に上回るように設定しています。 
バリデーションデータについては、MNISTの分類では必要と感じなかったため、用意していません。 


説明変数は、空間的な情報を損なわないように28*28のデータとしています。 
今回は後述するようにモデルとしてニューラルネットを用いるため、説明変数の取捨選択は行っていません。


モデル構築
----
### どのようなモデルを選んだか、どのようなアーキテクチャにしたのか
モデルとしては、畳み込み層1層と全結合層2層からなる畳み込みニューラルネットワーク(CNN)を採用しました。 
まず、ニューラルネットワークを採用した理由としては、特徴抽出を自動で行うことができるためです。画像から文字の特徴を抽出するにあたり、様々な特徴量の計算方法(フィルタなど)が提案されていますが、それら1つ1つを吟味することは大変な労力が必要です。一方、ニューラルネットであれば自動で分類に適した特徴量を抽出し、大幅にコストが低いためニューラルネットワークを採用しました。 
畳み込み層を用いた理由としては、畳み込み層によって空間的な特徴を抽出することを期待したためです。仮に全結合層だけを用いていた場合は、画像を一次元の数字の羅列として捉えるため、空間的な特徴は捉えれらないと考えました。 
ドロップアウト層を用いた理由は、単に精度向上のためです。 



### モデル学習時のハイパーパラメーター等、学習方法について
ハイパーパラメータ―を決める前提として、以下にある各種パラメータは、accuracyなどの微調整はしていないです。
理由としては、kaggleに提出する場合としない場合でデータセットの制約が変化するなど、問題の条件が不明瞭であったためです。

ハイパーパラメータは次のように設定しています。 
損失関数には、多クラス分類であることを考慮してCross Entropyを用いました。 
最適化関数には、SGDでは収束に時間がかかるため、学習速度の観点からAdamを採用しました。 
学習率は、損失が発散することを防ぐため、0.001と小さめの値にしました。 
バッチサイズについては、メモリの都合もあって64にしています。 
epochに関しては、3epochとしています。これは、むやみにepoch数を大きくしてもオーバーフィットする恐れがあるためです。本来であれば、early stoppingなどを用いて、オーバーフィットしないギリギリまで学習することで精度向上につながります。しかし、何度かテストした際は3epochの学習で、テストデータにおいてある程度のaccuracyが出ていたため、epoch数の調整は行いませんでした。 
また、交差検証は行っていません。MNISTでは、モデルの汎化性能を試すほどの理由がなかったためです。 


学習方法については、バッチ単位でlossを計算し、Backpropagationを用いて、CNNの各層の重みを更新しました。


テスト結果
----
### 手書き数字の識別結果をrecall、precision、f-score
recall      :0.99 
precision   :0.99 
f-score     :0.99 

コード実行手順
----
ノートブック形式なので、上のセルから順に実行すると、データの前処理やモデル構築、学習からテストまで順次行われます。

その他
----
ノートブックの末尾に混同行列や特徴量空間の可視化など分析用のコードを幾つか載せています。