{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596557661239",
   "display_name": "Python 3.7.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 手書き文字分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8eaeb9637177>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 1. ライブラリインポートと学習データのダウンロード\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# 1. ライブラリインポートと学習データのダウンロード\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "data_path = './drive/My Drive/machine_learning/dataset'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "X, y = fetch_openml('mnist_784', data_home=data_path, version=1, return_X_y=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データの前処理\n",
    "X = X / 255\n",
    "y = [float(s) for s in y]\n",
    "\n",
    "\n",
    "X = np.reshape(X,(70000,28,28))\n",
    "X = X[:,np.newaxis,:,:]\n",
    "print('detaset shape',X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#学習データ表示\n",
    "\n",
    "plt.imshow(X[-1,0,:,:], cmap=plt.cm.gray)\n",
    "print(\"{:.0f}\".format(y[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再現性担保のための乱数固定\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセット作成\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/7, random_state=0)\n",
    "\n",
    "print(type(y_train[0]))\n",
    "print(X_train[0].shape)\n",
    "\n",
    "X_train = torch.Tensor(X_train)\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)\n",
    "\n",
    "ds_train = TensorDataset(X_train, y_train)\n",
    "ds_test = TensorDataset(X_test, y_test)\n",
    "\n",
    "loader_train = DataLoader(ds_train, batch_size=64, shuffle=True)\n",
    "loader_test = DataLoader(ds_test, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル設計\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3) # 28x28x32 -> 26x26x32\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3) # 26x26x64 -> 24x24x64 \n",
    "        self.pool = nn.MaxPool2d(2, 2) # 24x24x64 -> 12x12x64\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.dropout1 = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(12 * 12 * 64, 128)\n",
    "        self.dropout2 = nn.Dropout2d()\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "      \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = x.contiguous().view(-1, 12 * 12 * 64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "model = CNN()\n",
    "\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 誤差関数と最適化手法の設定\n",
    "\n",
    "from torch import optim\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 学習の設定\n",
    "\n",
    "def train(epoch):\n",
    "  model.train()\n",
    "\n",
    "  for data, targets in loader_train:\n",
    "    data, targets = data.cuda(), targets.cuda()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(data)\n",
    "    loss = loss_fn(outputs, targets)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  print(\"epoch{}:終了\\n\".format(epoch))\n",
    "\n",
    "\n",
    "\n",
    "# 推論の設定\n",
    "\n",
    "def test():\n",
    "  model.eval()\n",
    "  correct = 0\n",
    "  predicted_score = torch.zeros(y_test.size()[0])\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for idx,(data, targets) in enumerate(loader_test):\n",
    "      data, targets = data.cuda(), targets.cuda()\n",
    "\n",
    "      outputs = model(data)\n",
    "\n",
    "      _, predicted = torch.max(outputs.data, 1)\n",
    "      predicted_score[idx*64:(idx+1)*64] = predicted\n",
    "      correct += predicted.eq(targets.data.view_as(predicted)).sum()\n",
    "\n",
    "  data_num = len(loader_test.dataset)\n",
    "  print('\\nテストデータの正解率：{}/{}({:.0f}%)\\n'.format(correct, data_num, 100. * correct /data_num))\n",
    "\n",
    "  return predicted_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習前のテストデータ正解率\n",
    "\n",
    "_ =  test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 学習後のテストデータ正解率\n",
    "\n",
    "for epoch in range(3):\n",
    "  train(epoch)\n",
    "\n",
    "y_pred = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下、考察用データ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 混同行列の作成\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 間違えたサンプルの抽出と一部図示\n",
    "\n",
    "model.eval()\n",
    "mis_recog = set() \n",
    "\n",
    "for idx in range(X_test.shape[0]):\n",
    "  data = X_test[idx]\n",
    "  data = data[np.newaxis,:,:]\n",
    "  data = data.cuda()\n",
    "  output = model(data)\n",
    "  _, predicted = torch.max(output.data[0], 0)\n",
    "\n",
    "  if int(predicted) is not int(y_test[idx]):\n",
    "    mis_recog.add((idx,int(predicted)))\n",
    "\n",
    "mis = list(mis_recog)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(3, 3))\n",
    "\n",
    "from pylab import rcParams\n",
    "\n",
    "rcParams['figure.figsize'] = 20,20\n",
    "\n",
    "# 余白を設定\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.6)\n",
    "for i,idx in enumerate(mis[:9]):\n",
    "    x = X_test[idx[0]]\n",
    "    im = x.view(-1, 28, 28).permute(1, 2, 0).squeeze().numpy()\n",
    "    ax = fig.add_subplot(3, 3, i+1, xticks=[], yticks=[])\n",
    "    ax.set_title('T:'+str(int(y_test[idx[0]]))+' Pred:'+str(idx[1]),pad=0)\n",
    "    ax.imshow(im, 'gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像データから特徴量抽出\n",
    "\n",
    "features_test = []\n",
    "\n",
    "for idx in range(X_test.shape[0]):\n",
    "    tmp = X_test[np.newaxis,idx,:,:]\n",
    "    tmp = tmp.cuda()\n",
    "    tmp = model.encoder(tmp)\n",
    "    tmp = tmp.reshape(-1)\n",
    "    tmp = tmp.cpu().detach().numpy()\n",
    "    features_test.append(tmp)\n",
    "\n",
    "features_train = []\n",
    "\n",
    "for idx in range(X_train.shape[0]):\n",
    "    tmp = X_train[np.newaxis,idx,:,:]\n",
    "    tmp = tmp.cuda()\n",
    "    tmp = model.encoder(tmp)\n",
    "    tmp = tmp.reshape(-1)\n",
    "    tmp = tmp.cpu().detach().numpy()\n",
    "    features_train.append(tmp)\n",
    "\n",
    "features_train = np.array(features_train)\n",
    "features_test = np.array(features_test)\n",
    "\n",
    "features = np.vstack((features_train,features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#メモリ確保のための変数除去\n",
    "\n",
    "del features_test\n",
    "del features_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主成分分析を用いて特徴量の次元削減\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=30)\n",
    "pca.fit(features)\n",
    "reduced_feature = pca.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#メモリ確保のための変数除去\n",
    "\n",
    "del features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# umapによる特徴量空間の可視化\n",
    "import umap\n",
    "\n",
    "mapper = umap.UMAP()\n",
    "umap_embedding = mapper.fit_transform(reduced_feature)\n",
    "\n",
    "cmap = plt.get_cmap(\"tab10\") \n",
    "\n",
    "for idx in range(y_train.shape[0]):\n",
    "    plt.plot(umap_embedding[idx,0],umap_embedding[idx,1],marker='$'+str(int(y_train[idx]))+'$',markersize=10,color=cmap(int(y_train[idx])))\n",
    "\n",
    "for idx in mis:\n",
    "    plt.plot(umap_embedding[idx[0]+60000,0],umap_embedding[idx[0]+60000,1],marker='$'+str(int(y_test[idx[0]]))+'$',markersize=10,color='k')\n",
    "\n",
    "print('形:true class')\n",
    "print('色:黒→test dataで誤分類したサンプル　その他→train dataで、同色は同じクラス')"
   ]
  }
 ]
}